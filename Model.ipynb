{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allay\\Anaconda3\\envs\\gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat May 12 15:08:40 2018\n",
    "\n",
    "@author: Allay\n",
    "\"\"\"\n",
    "# import libraries\n",
    "import csv\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.layers import Input, Flatten, Dense, Lambda\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, sys\n",
    "import settings\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# define flags:\n",
    "#flags = tf.app.flags\n",
    "#FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('data_path', '', 'Path to data folder')\n",
    "#flags.DEFINE_string('training_file', '', 'Pickle file of training data')\n",
    "#flags.DEFINE_string('validation_file', '', 'Pickle file of validation data')\n",
    "#flags.DEFINE_integer('epochs', 1, 'Number of epochs')\n",
    "\n",
    "\n",
    "# Load file paths\n",
    "def LoadRawData(path):\n",
    "    with open(path+'driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        lines = [line for line in reader]\n",
    "    # load data: images and measurements\n",
    "    images = np.array([cv2.imread(line[0]) for line in lines])\n",
    "    measurements = np.array([float(line[3]) for line in lines])\n",
    "    return images, measurements\n",
    "\n",
    "def PrintStats():\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    #n_test = X_test.shape[0]\n",
    "    image_shape = X_train.shape[1:]\n",
    "    n_classes, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "    print(\"Number of training examples =\", n_train)\n",
    "    #print(\"Number of validation examples =\", n_val)\n",
    "    print(\"Number of testing examples =\", n_test)\n",
    "    print(\"Image data shape =\", image_shape)\n",
    "    print(\"Labels data shape =\", y_train.shape)\n",
    "    \n",
    "def LoadFromPickleFile():\n",
    "    print('Loading data from pickle file...')\n",
    "    for filename in os.listdir(settings.DATA_PATH):\n",
    "        if filename == settings.DATA_PICKLE_FILENAME:\n",
    "            try:\n",
    "                with open(settings.DATA_PATH + filename, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    return data['train_dataset'], data['train_labels'], data['test_dataset'], data['test_labels']\n",
    "            except:\n",
    "                print('Unable to load training data from pickle file')\n",
    "                raise\n",
    "            \n",
    "    \n",
    "def SaveDataToPickleFile():\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open(settings.DATA_PATH + settings.DATA_PICKLE_FILENAME, 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': X_train,\n",
    "                    'train_labels': y_train,\n",
    "                    'test_dataset': X_test,\n",
    "                    'test_labels': y_test,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', settings.DATA_PICKLE_FILENAME, ':', e)\n",
    "        raise\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from pickle file...\n",
      "Number of training examples = 5354\n",
      "Number of testing examples = 945\n",
      "Image data shape = (160, 320, 3)\n",
      "Labels data shape = (5354,)\n"
     ]
    }
   ],
   "source": [
    "#def main(_):\n",
    "# load data\n",
    "#check if pickle file exists\n",
    "if os.path.isfile(settings.DATA_PATH + settings.DATA_PICKLE_FILENAME):\n",
    "    X_train, y_train, X_test, y_test = LoadFromPickleFile()\n",
    "else:\n",
    "    X_train, y_train = LoadRawData(settings.DATA_PATH)#FLAGS.data_path)\n",
    "    # Split data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=0)\n",
    "    # Create pickle file for future use\n",
    "    SaveDataToPickleFile()\n",
    "    print('Data cached in pickle file.')\n",
    "\n",
    "PrintStats()\n",
    "\n",
    "# pre-process data\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4283 samples, validate on 1071 samples\n",
      "Epoch 1/2\n",
      "4283/4283 [==============================] - 3s 779us/step - loss: 6.0444 - acc: 0.2071 - val_loss: 0.4242 - val_acc: 0.4127\n",
      "Epoch 2/2\n",
      "4283/4283 [==============================] - 3s 757us/step - loss: 1.2732 - acc: 0.2848 - val_loss: 0.6986 - val_acc: 0.3688\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam',  metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=2)#settings.EPOCHS)\n",
    "\n",
    "print('Saving model...')\n",
    "model.save(settings.MODEL_FILENAME)\n",
    "\n",
    "\n",
    "    \n",
    "# parses flags and calls the `main` function above\n",
    "#if __name__ == '__main__':\n",
    "#    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "945/945 [==============================] - 1s 562us/step\n",
      "loss: 0.6688937895827823\n",
      "acc: 0.38941798963874735\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
